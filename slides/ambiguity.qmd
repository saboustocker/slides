---
title: "Origin Ambiguity"
author: Sabou Rani Stocker
date: 2025-10-29
subtitle: What happens if people no longer know if something originates from AI or human authorship? 
format:
  html:  
    theme: [sandstone, hsg_pages.scss]
    navbar: false
title-slide-attributes: 
  data-background-color: "#0a5f2d"
project: "AI assessment"
bibliography: ../bibliography.bib
---

# Synthesis of existing Research
1. Differences in perception of trustworthiness, purchase intention, attribution & responsibility, and behavior 
2. Ability to differentiate between human origin and AI origin 
3. Consequences of ambiguity of origin
4. Legal grounds for disclosure 

## Differences between Human and AI origin
### Trustworthiness 
- people trust AI less than humans in various contexts:
  - AI is perceived to lack human abilities [@kirkAIauthorshipEffectUnderstanding2025; @lefkeliSharingInformationAI2024]
    - which leads to perceived human decision-makers in the background, which in turn leads to perceived reduction in privacy and increase in feeling exploitet [@lefkeliSharingInformationAI2024]
  - AI is perceived as less private [@lefkeliSharingInformationAI2024]
  - trust is decreased more if AI use is disclosed [@schilkeTransparencyDilemmaHow2025; @kirkAIauthorshipEffectUnderstanding2025] ...
  - ... and people trust AI less when disclosing things [@lefkeliSharingInformationAI2024]
- some of these effects (e.g. algorithm aversion 
[@bigmanAlgorithmicDiscriminationCauses2022]) have been discussed extensively already
- @pfeufferIllegallyBeautifulRole2025 show that disclosing the alteration of images decreases trust in content creators / brands

> [!NOTE] Notes
> This is basically "done" at least from the POV of getting any of this published.
> Trust as an attitude is a pretty basic and thus relatively uninteresting variable imo. It is just a positively valenced variable that can capture both cognitive and affective dimensions, thus it might work as mediator whenever there is either a positive or negative outcome.


### Purchase Intention
- the use of AI decreases the intention to purchase a product, the product loyalty and the willingness to recommend a product 
  - if communication is perceived to be written by AI [@kirkAIauthorshipEffectUnderstanding2025]
  - if generated imagery is generated by AI [@belancheCustomerReactionsGenerative2025]
    - especially for hedonic services [@belancheCustomerReactionsGenerative2025]
  - ... but if people trust AI, the effect is mitigated [@jungArtificialCreativityLuxury2025]
  - ... and perceived humanness of AI increases purchase intention [@jungArtificialCreativityLuxury2025]


> [!NOTE] Note
> My general suggestion would be to look at something that goes beyond purchase/acceptance. The dominant paradigm over the last years has been this aversion vs. acceptance debate. I think we have considerably more upside, if we focus on a more up- or downstream variable along consumers' journeys with AI (which can be a variable with impact on business or consumers' self concept etc.). That means, we think about something that is prior to acceptance or not directly relevant to it or we look at usage/interaction etc.

### Attribution & Responsibility
- because AI is perceived as lacking human abilities [@lefkeliSharingInformationAI2024; @bigmanAlgorithmicDiscriminationCauses2022], responsibility is shifted to "humans in the background"
- This leads to perceiving AI as less biased ...[@feldkampJusticeTrustMoral2024; @bigmanAlgorithmicDiscriminationCauses2022; @bonezziCanAlgorithmsLegitimize2021; @bedemariamRolesOutcomeRace2023]
- ... and to less moral outcry when AI makes "biased" decisions [@feldkampJusticeTrustMoral2024; @bigmanAlgorithmicDiscriminationCauses2022; @bonezziCanAlgorithmsLegitimize2021; @bedemariamRolesOutcomeRace2023]

### Behavior
- People display themselves as more analytical when they believe they are assessed by AI instead of humans [@goergenAIAssessmentChanges2025]
- ... (more phenomena in that direction to be researched)

## Ability to Differenciate between Human and AI origin
- “almost 50% of respondents can distinguish between AI and human generated artwork.” [@vukojicicImitationDrawingCan2023]
- “participants performed below chance levels in identifying AI-generated poems (46.6% accuracy)" [@porterAIgeneratedPoetryIndistinguishable2024a]
“participants were more likely to judge AI-generated poems as human-authored than actual human-authored poems [@porterAIgeneratedPoetryIndistinguishable2024a]
- non-artists have pronounced difficulty identifying AI generated images [@haOrganicDiffusedCan2024], but artists and professional artists had much less difficulty [@haOrganicDiffusedCan2024]
- However, @youDistinguishingAIImage2024 did not find a difference between creators and non-creators in accuracy of identifying images
- AI generated image detectors (e.g. Hive) had no difficulty detecting AI generated images [@haOrganicDiffusedCan2024]
- With training, participants were able to correctly identify AI generated text correctyl 65% of the time; without training 55% - i.e. slightly above chance [@milickaHumansCanLearn2025]

## Consequences in Ambiguity of Marketing Materials
- there is very little research on how ambiguity of origin (and authenticity) affect consumer perception, however: 
  - @whittakerExaminingConsumerAppraisals2025 show that perception of AI alteration (with deepfakes) decreases intention to purchase, and humanness of deepfake increases perceived authenticity
  - @silverInauthenticityAversionMoral2021 show that perceived inauthenticity increases outrage at brands. One core driver of perceived inauthenticity is deception, another one is adulteration (i.e. "enhancing")
  - the *uncanny valley* effect is perceived as highly unpleasant [@seyamaUncannyValleyEffect2007]


> [!NOTE] Note
> This is interesting. What does feeling ambiguity related to content origin (or something else in AI realm) do with the consumer? Feeling unease, compensatory behavior (in other domain), outrage, what inferences do consumers draw under ambiguity?, how do consumers deal with ambiguity in general --> we probably fall back on some heuristics, can we identify a new one here and any consequences? 

> [!NOTE] Idea
> How many people are actually experiencing this kind of ambiguity? Under **TikTok videos (define domain)**, we could probably find references to "Is this AI?" that would be perfect ambiguity markers. **That is descriptive in a first step. But then what other variables could be interesting to look at here?** What does this ambiguity do to the video's performance in terms of engagment etc. (issue will be control group, so potentially just correlative). What are ambiguity markers that consumers mention, **what makes them certain of the origin?** 
> Where is the marketing relevance? We either do a pure consumer story (it does something with the consumer, wellbeing, self-concept etc.) or we extrapolate to companies that use AI for ads or so: What does ambiguity do with brand attitudes etc. (there is a gap here, I suppose)

## Legal Grounds on Disclosure of the Use of AI
- there are no universal provisions to mandate AI disclosure ([Vischer, 2024](https://www.vischer.com/en/knowledge/blog/part-16-how-company-can-ensure-transparency-for-their-use-of-ai/))
- the existing laws leave enough leeway for companies to utilize AI without disclosure, justifying the question as to how consumers react when origin is ambiguous
  - GDPR / FADP as part of the duty to inform people when personal data is obtained to be used with any sort of AI system (GDPR Art. 13/14, FADP Art. 19ff) and for which purposes (GDPR Art. 5(1) and FADP Art. 6(2-3)), as well as in the context of consent (GDPR Art. 4(11) & FADP Art. 6(6))
  - Swiss Labour Act (Ordinance 3, Art. 26) prohibits behavioral monitoring in the workplace unless required. In that case they must be disclosed (Ordinance 3, Art. 6)
  - Federal Act on Cartels and other Restraints of Competition and the Federal Act on Unfair Competition(CH) provides some regulations on transparency, copyright of competitors, and targeting ([CartA](https://www.fedlex.admin.ch/eli/cc/1996/546_546_546/en),[UCA](https://www.fedlex.admin.ch/eli/cc/1988/223_223_223/en))
  - The United States have several state-wide bills which regulate some uses of AI (e.g. [AI transparency Act](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202520260AB853) in California or the [Colorado AI Act](https://leg.colorado.gov/sites/default/files/2024a_205_signed.pdf)).
  - copyright laws
  - the AI Act in the EU (see next page for excerpts)
  - and more

### The AI Act (EU)
Providers shall ensure that AI systems intended to interact directly with natural persons are designed and developed in such a way that the natural persons concerned are informed that they are interacting with an AI system, unless this is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect, taking into account the circumstances and the context of use. This obligation shall not apply to AI systems authorised by law to detect, prevent, investigate or prosecute criminal offences, subject to appropriate safeguards for the rights and freedoms of third parties, unless those systems are available for the public to report a criminal offence.

Providers of AI systems, including general-purpose AI systems, generating synthetic audio, image, video or text content, shall ensure that the outputs of the AI system are marked in a machine-readable format and detectable as artificially generated or manipulated.

Deployers of an AI system that generates or manipulates image, audio or video content constituting a deep fake, shall disclose that the content has been artificially generated or manipulated. This obligation shall not apply where the use is authorised by law to detect, prevent, investigate or prosecute criminal offence. 

Where the content forms part of an evidently artistic, creative, satirical, fictional or analogous work or programme, the transparency obligations set out in this paragraph are limited to disclosure of the existence of such generated or manipulated content in an appropriate manner that does not hamper the display or enjoyment of the work.

The information referred to in paragraphs 1 to 4 shall be provided to the natural persons concerned in a clear and distinguishable manner at the latest at the time of the first interaction or exposure. 

[AI Act, Art. 50](https://artificialintelligenceact.eu/article/50/#:~:text=If%20an%20AI%20system%20creates,content%20is%20artistic%20or%20satirical.)

### Copyright
- In general, AI generated materials cannot be copyrighted by companies 

## Identifying the Gap
### What we know
- People prefer human over AI
- Organizations and Companies tend to prefer AI over human due to efficiency and cost*
- People are bad at identifying AI generated content
- The law does not provide clear regulations on the (mandated) disclosure of AI, and research shows that AI disclosure decreases trust and purchase intention $\rightarrow$ motivation for companies to not disclose the use of AI

*although it must be noted that many of these AI applications are still works in progress as well, and this sentiment could very well shift

### What is missing?
- Research on perception of AI- vs. human origin discloses AI vs. human origin $\rightarrow$ this is not the case in the real world
- Does, and if yes, *how* does response differ in uncertain territory?

![](../images/areaofinterest.svg)

### Why it matters
- there is legitimate interest on the side of companies to not disclose AI (negative effects of disclosure: [@whittakerExaminingConsumerAppraisals2025;@schilkeTransparencyDilemmaHow2025;@lefkeliSharingInformationAI2024])
- To the best of my knowledge, there are not yet any studies analyzing the effect ambiguity of origin has on consumer perception of marketing and products
- **(help here needed)**

# Moving Forward

## Next Steps
- Is this research area substantial enough to make a project out of it? 
- What key considerations are we missing to make a project out of it? 

# Bibliography